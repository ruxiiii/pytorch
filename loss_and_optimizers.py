# -*- coding: utf-8 -*-
"""loss_and_optimizers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ot4F02Sos7pSfiBXI908JXzauegrP6J7
"""

import torch

#prediction and paramter using pytorch

'''designing model using input, output size, forward pass
2. construct loss and optimizer
3. training loop
4. updating the weights
'''

import torch.nn as nn

#defining learning rate and epochs, weights
learning_rate = 0.01
n_iters = 100
w = torch.tensor(0.0,requires_grad=True,dtype=torch.float32)
x = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)
y = torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)

n_samples,n_features = x.shape
print(n_samples,n_features)


x_test = torch.tensor([5],dtype = torch.float32)

input_size = n_features
output_size = n_features

model = nn.Linear(input_size,output_size)

#custom linear regression model
'''class LinearRegression(nn.Module):

  def __init__(self,input_dim,output_dim):
    super(LinearRegression,self).__init__()
    #define layers
    self.lin = nn.Linear(input_dim,output_dim)
  def forward(self,x):
    return self.lin(x)
    '''


#loss function calculates mean squared loss
loss = nn.MSELoss()

#optimizer updates the weights and learning rate
optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)


print(f'Prediction before training: f(5) = {model(x_test).item():.3f}')

for epoch in range(n_iters):
  y_pred = model(x)
  l = loss(y,y_pred)

  #would compute the gradients
  l.backward()

  #updates weights
  optimizer.step()

  #empties the gradient
  optimizer.zero_grad()
  if epoch % 10 == 0:
      [w,b] = model.parameters()
      print(f'epoch {epoch+1}: w = {w[0][0] :.3f}, loss = {l.item():.8f}')

print(f'Prediction after training: f(5) = {model(x_test).item():.3f}')















